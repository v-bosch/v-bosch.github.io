---
layout: distill
title: CorText
description: Large language models for cross-modal transformations from visually evoked brain responses to text captions
img: assets/img/cortext_thumbnail.png
importance: 1
category: work
visible: false
#related_publications: einstein1956investigations, einstein1950meaning

# authors:
#   - name: Victoria Bosch
#     affiliations:
#       name: Osnabrück University
#   - name: Dirk Gütlin
#     affiliations:
#       name: Freie Universität Berlin
#   - name: Adrien Doerig
#     affiliations:
#       name: Osnabrück University
#   - name: Daniel Anthes
#     affiliations:
#       name: Osnabrück University
#   - name: Sushrut Thorat
#     affiliations:
#       name: Osnabrück University
#   - name: Peter König
#     affiliations:
#       name: Osnabrück University
#   - name: Tim C Kietzmann
#     affiliations:
#       name: Osnabrück University
#       email: tim.kietzmann@uos.de


# toc:
#   - name: Background
#   - name: Architecture
#   - name: Decoding
#   - name: Interpreting Attention
#   - name: Conclusion
#   - name: Citations

---

Here you can find the PDF of the short paper presented at CCN 2024: [pdf](/assets/pdf/Cortext_Bosch_CCN2024.pdf)

<!--**Abstract:**

_An emerging trend in cognitive neuroscience is to investigate neural responses to complex natural scenes. While more ecologically valid, the complexity of these stimuli requires analysis techniques capable of studying not only the neural responses to object categories that constitute a given scene, but also their rich spatial and semantic interactions. Here, we present a generative brain-totext decoder, CorText, that produces linguistic descriptions of natural scenes based on visually-evoked fMRI responses. At no point does the decoder have access to the visual stimulus, it operates solely on brain data. This cross-modal transformer, consisting of a linear encoder for neural data and a partly frozen pre-trained language decoder, enables us to harness the powerful features of language models to study neural representations. As a proof of concept, we analyse the neural regions most informative for generating specific words by visualising the transformer’s attention patterns. This approach reproduces known functional organisation: elevated attention in the ventral stream and, accordingly, attention in cortical regions involved in category-specific processing. This work thus marks an important first advance into end-to-end generative language transformers for investigating complex neural data._-->
